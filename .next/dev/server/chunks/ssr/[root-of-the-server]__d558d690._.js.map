{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 13, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/components/NavBar.module.css [app-rsc] (css module)"],"sourcesContent":["__turbopack_context__.v({\n  \"brand\": \"NavBar-module__8u-qnq__brand\",\n  \"link\": \"NavBar-module__8u-qnq__link\",\n  \"nav\": \"NavBar-module__8u-qnq__nav\",\n  \"navlinks\": \"NavBar-module__8u-qnq__navlinks\",\n});\n"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA"}},
    {"offset": {"line": 23, "column": 0}, "map": {"version":3,"sources":["file:///Users/andrewgordienko/Documents/andrewgordienko-website/components/NavBar.tsx"],"sourcesContent":["import Link from \"next/link\";\nimport styles from \"./NavBar.module.css\";\n\nexport default function NavBar() {\n  return (\n    <header className={styles.nav}>\n      <Link href=\"/\" className={styles.brand}>\n        &lt;Andrew /&gt;\n      </Link>\n\n      <nav className={styles.navlinks}>\n        <Link href=\"/resume\" className={styles.link}>\n          RESUME\n        </Link>\n        <Link href=\"/contact\" className={styles.link}>\n          CONTACT\n        </Link>\n      </nav>\n    </header>\n  );\n}\n"],"names":[],"mappings":";;;;;AAAA;AACA;;;;AAEe,SAAS;IACtB,qBACE,8OAAC;QAAO,WAAW,2IAAM,CAAC,GAAG;;0BAC3B,8OAAC,0LAAI;gBAAC,MAAK;gBAAI,WAAW,2IAAM,CAAC,KAAK;0BAAE;;;;;;0BAIxC,8OAAC;gBAAI,WAAW,2IAAM,CAAC,QAAQ;;kCAC7B,8OAAC,0LAAI;wBAAC,MAAK;wBAAU,WAAW,2IAAM,CAAC,IAAI;kCAAE;;;;;;kCAG7C,8OAAC,0LAAI;wBAAC,MAAK;wBAAW,WAAW,2IAAM,CAAC,IAAI;kCAAE;;;;;;;;;;;;;;;;;;AAMtD"}},
    {"offset": {"line": 84, "column": 0}, "map": {"version":3,"sources":["file:///Users/andrewgordienko/Documents/andrewgordienko-website/components/ProjectEmbed.tsx"],"sourcesContent":["export default function ProjectEmbed({ src }: { src: string; title?: string }) {\n  const isPdf = src.toLowerCase().endsWith(\".pdf\");\n\n  // Try to hide browser PDF UI (works well in Chrome/Edge/Firefox)\n  // toolbar=0 removes top toolbar\n  // navpanes=0 removes left thumbnail pane\n  // view=FitH fits to width\n  const pdfSrc = isPdf\n    ? `${src}#toolbar=0&navpanes=0&scrollbar=1&view=FitH`\n    : src;\n\n  return (\n    <div className=\"embedFrame\">\n      <div className=\"embedTopBar\">\n        <span className=\"dot red\" />\n        <span className=\"dot yellow\" />\n        <span className=\"dot green\" />\n      </div>\n\n      <div className=\"embedViewport\">\n        {isPdf ? (\n          <iframe className=\"embedPdf\" src={pdfSrc} title=\"PDF preview\" />\n        ) : (\n          <iframe\n            className=\"embedSite\"\n            src={src}\n            title=\"Project preview\"\n            loading=\"lazy\"\n            referrerPolicy=\"no-referrer\"\n            sandbox=\"allow-scripts allow-same-origin allow-forms allow-popups\"\n          />\n        )}\n      </div>\n    </div>\n  );\n}\n"],"names":[],"mappings":";;;;;;AAAe,SAAS,aAAa,EAAE,GAAG,EAAmC;IAC3E,MAAM,QAAQ,IAAI,WAAW,GAAG,QAAQ,CAAC;IAEzC,iEAAiE;IACjE,gCAAgC;IAChC,yCAAyC;IACzC,0BAA0B;IAC1B,MAAM,SAAS,QACX,GAAG,IAAI,2CAA2C,CAAC,GACnD;IAEJ,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC;gBAAI,WAAU;;kCACb,8OAAC;wBAAK,WAAU;;;;;;kCAChB,8OAAC;wBAAK,WAAU;;;;;;kCAChB,8OAAC;wBAAK,WAAU;;;;;;;;;;;;0BAGlB,8OAAC;gBAAI,WAAU;0BACZ,sBACC,8OAAC;oBAAO,WAAU;oBAAW,KAAK;oBAAQ,OAAM;;;;;yCAEhD,8OAAC;oBACC,WAAU;oBACV,KAAK;oBACL,OAAM;oBACN,SAAQ;oBACR,gBAAe;oBACf,SAAQ;;;;;;;;;;;;;;;;;AAMpB"}},
    {"offset": {"line": 168, "column": 0}, "map": {"version":3,"sources":["file:///Users/andrewgordienko/Documents/andrewgordienko-website/app/projects/data.ts"],"sourcesContent":["// app/projects/data.ts\n\nexport type PillTone = \"companies\" | \"simulation\" | \"research\";\n\nexport type Project = {\n  slug: string;\n  title: string;\n  subtitle: string;\n  role: string;\n\n  pill: string;\n  pillTone: PillTone;\n\n  desc: string;\n  longDesc: string;\n\n  href: string; // external site or internal route\n  embedUrl?: string; // external iframe preview (if allowed)\n\n  comingSoon?: boolean;\n};\n\nexport const projects: Project[] = [\n  {\n    slug: \"outagehub\",\n    title: \"OutageHub\",\n    subtitle: \"CanadianPowerOutages.ca\",\n    role: \"Founder and CEO\",\n    pill: \"Enterprise / Infrastructure\",\n    pillTone: \"companies\",\n    desc:\n      \"A real-time power outage map and API for Canada. Aggregation, normalization, and delivery of outage data with a focus on reliability and speed.\",\n    longDesc: `\n## The problem\nWhen the internet goes down, it is surprisingly hard to answer a simple question: is this a local network issue, or is the power out?\n\nFor telecom teams, this matters. Sending trucks is expensive, slow, and often the wrong first move if you do not have good situational awareness. Customers feel the delay, operations waste money, and everyone ends up working from guesses.\n\n## How it started\nOutageHub began after we were approached to build a lightweight way to verify power outages in an area. The goal was operational: help support and field teams separate “internet is down” from “power is out” quickly, so decisions get made with real information instead of assumptions.\n\n## The first prototype\nI built an early prototype in Python to prove the concept and map the scope. It worked well enough to show the value immediately, but it also made the real challenge obvious:\n\nIf this is going to matter during live outage conditions, it needs to be reliable.\n\nThat does not just mean “the site loads.” It means the data model needs to be consistent, the update path needs to hold up, and the UI needs to stay usable when people actually need it.\n\n## Turning it into infrastructure\nOnce the scope was clear, I brought in a few friends and we started turning it into a real system.\n- ingestion across multiple sources\n- normalization into one consistent model\n- reliability under live conditions\n- a public map plus an API teams can integrate directly\n\nThe hard part is not the map. The hard part is taking messy, incomplete, inconsistent outage information and making it usable in real time.\n\n## Validation and real-world conversations\nSince then, we have spoken with utilities, charities, and multiple levels of Canadian government to validate usefulness, test accuracy, and understand how this fits into real operations.\n\nA big part of the work is making sure this is not “cool tech.” It needs to be a tool people trust when the situation is messy and high-pressure.\n\n## Where it is now\nRight now, the focus is reliability and validation. The goal is simple: when outages are happening, the system needs to hold up and stay useful.\n`.trim(),\n    href: \"https://canadianpoweroutages.ca\",\n    embedUrl: \"https://canadianpoweroutages.ca\",\n  },\n\n  {\n    slug: \"gnk-software\",\n    title: \"G&K Software\",\n    subtitle: \"Modernization contracts\",\n    role: \"Head of Sales\",\n    pill: \"Enterprise / Delivery\",\n    pillTone: \"companies\",\n    desc:\n      \"We help teams modernize legacy systems through carve-outs, integration layers, data tooling, and testing support alongside larger programs.\",\n    longDesc: `\n## What G&K does\nG&K Software is a small senior delivery team focused on modernization work that needs precision.\n\nA lot of modernization programs fail in predictable ways. The problem is not motivation or budget. It is delivery detail: unclear boundaries, integration pain, weak testing scaffolding, or data work that becomes a permanent blocker.\n\nWe focus on the work that is narrow, technical, and high-impact.\n\n## The kind of work we take on\nModernization is broad, but the parts that stall programs are usually the same:\n- service carve-outs and boundary extraction\n- integration layers and interface stabilization\n- downstream data tooling and validation pipelines\n- testing support that makes a larger program safer to ship\n\nThe goal is always the same: unblock delivery and reduce risk without turning the work into a multi-year rewrite.\n\n## Why this exists\nMost large transformation programs are run inside big teams, but the bottlenecks tend to form around specific pieces of work that need strong execution and fast turnaround.\n\nG&K is built to take those pieces, own them end-to-end, and deliver cleanly.\n\n## My role\nI run sales and early pipeline. That means:\n- outreach and relationship building\n- scoping and qualification\n- translating real pain into a small first engagement\n- keeping the conversation grounded in “what can we ship” instead of vague modernization language\n\nThe objective is straightforward: land the first contracts, deliver well, and expand from there.\n`.trim(),\n    href: \"https://gnk.software\",\n    embedUrl: \"https://gnk.software\",\n  },\n\n  {\n    slug: \"do-better-foundation\",\n    title: \"Do Better Foundation\",\n    subtitle: \"dobetterfoundation.com\",\n    role: \"Cofounder\",\n    pill: \"Enterprise / Policy\",\n    pillTone: \"companies\",\n    desc:\n      \"A research and tooling effort to find gaps in government policy and execution, starting with construction delays, using LLMs to surface patterns and root causes.\",\n    longDesc: `\n## The focus\nDo Better Foundation is about execution.\n\nA lot of public systems fail in predictable ways, but the evidence is scattered across reports, timelines, procurement documents, and fragmented accountability. The signal is there, but it is hard to see.\n\nThe goal is to build research and tooling that turns “everyone knows this is broken” into something measurable and explainable.\n\n## Why construction delays\nConstruction delays are one of the clearest examples of repeated failure patterns:\n- timelines slip in similar ways across projects\n- bottlenecks repeat, but the explanations are inconsistent\n- the cost of delay is real and compounding\n\nIt is a space with enough public data to analyze, and enough operational complexity that you cannot solve it with a single spreadsheet.\n\n## What we are building\nThe core idea is simple: pull the evidence together, then surface patterns.\n- collect documents and structured sources\n- normalize what “delay” actually means across contexts\n- extract recurring root causes\n- generate outputs that are actionable and explainable\n\nLLMs help, but only as part of a real system. The goal is not text generation. The goal is clarity: what is failing, where, and why.\n\n## Where it is now\nWe are building the foundations and validating what is actually useful to the people closest to the problem.\n\nThe bar is high. If this is going to matter, it needs to produce answers that are practical and defensible, not just “interesting analysis.”\n`.trim(),\n    href: \"#\",\n    comingSoon: true,\n  },\n\n  {\n    slug: \"bike-rebalance\",\n    title: \"Bike Rebalance Simulator\",\n    subtitle: \"Toronto Bike Share optimization\",\n    role: \"Builder\",\n    pill: \"Simulation / Optimization\",\n    pillTone: \"simulation\",\n    desc:\n      \"A simulation and optimization project to forecast station shortages and generate rebalance plans, including event-driven demand signals.\",\n    longDesc: `\n## The problem\nBike share systems have a simple failure mode: stations empty out or fill up at the wrong times.\n\nIt is not enough to know that demand exists. You need to know where bikes will be missing, when it will happen, and what interventions actually fix it.\n\n## What I built\nThis project is a simulator for station inventory over time, driven by real trip data.\n\nThe goal is a full loop from data to decision:\n- ingest ride events and station state\n- simulate inventory movement across the day\n- forecast shortages and overflows\n- produce actionable rebalancing moves\n\n## Why it matters\nA lot of bike share “analysis” stops at charts. This is meant to be operational: given a day and a fleet, what should you actually do?\n\nI also explored event-driven demand signals (games, concerts, major events) to capture the spikes that normal baselines miss.\n\n## Status\nIn progress. The core loop works and the next steps are expanding scenario coverage and producing cleaner decision outputs that match real operational constraints.\n`.trim(),\n    href: \"http://155.138.143.63/rebalance/\",\n    embedUrl: \"http://155.138.143.63/rebalance/\",\n  },\n\n  {\n    slug: \"f1-simulator\",\n    title: \"F1 Simulator\",\n    subtitle: \"In progress\",\n    role: \"Builder\",\n    pill: \"Simulation / Motorsports\",\n    pillTone: \"simulation\",\n    desc:\n      \"A racing sim playground to explore vehicle dynamics, overtakes, track geometry, and performance engineering workflows.\",\n    longDesc: `\n## Why I started it\nI wanted a sandbox where I could explore racing engineering problems without relying on black-box tooling.\n\nThe goal is not “make a game.” The goal is to create an environment where you can build intuition, test ideas, and iterate quickly.\n\n## What it covers\nThe simulator focuses on the parts of racing that are interesting from a systems perspective:\n- vehicle dynamics and control stability\n- track geometry, tangents, and constraints\n- overtakes and multi-agent interactions\n- performance tooling and visualization workflows\n\n## The point\nThis is an engineering playground. It lets me treat racing like an applied optimization and control problem, with just enough realism to make the tradeoffs meaningful.\n\n## Status\nIn progress. I’m building it as a long-running project with the goal of reaching “useful tool” quality, not just a demo.\n`.trim(),\n    href: \"#\",\n    comingSoon: true,\n  },\n\n  {\n    slug: \"chess-engine\",\n    title: \"Chess Engine\",\n    subtitle: \"In progress\",\n    role: \"Builder\",\n    pill: \"Simulation / Games\",\n    pillTone: \"simulation\",\n    desc:\n      \"A chess engine and interactive sandbox you can play with in-browser. Lightweight, fast iteration, and a clean analysis UI.\",\n    longDesc: `\n## The idea\nChess is one of the best environments for building systems that have to reason, search, and explain themselves.\n\nMost chess engines are impressive, but they are not always approachable. I wanted something fast to iterate on, and easy to inspect.\n\n## What I’m building\nA lightweight chess engine paired with an interactive UI.\n- search + evaluation loop\n- clean analysis view for lines and alternatives\n- a setup that makes it easy to test new ideas quickly\n\n## The goal\nNot just to play chess, but to make the engine’s reasoning visible.\n\n## Status\nIn progress. The focus is keeping the engine simple, fast, and hackable while still producing useful analysis.\n`.trim(),\n    href: \"http://155.138.143.63/hudson64/\",\n    embedUrl: \"http://155.138.143.63/hudson64/\",\n  },\n\n  {\n    slug: \"hybrid-locomotion\",\n    title: \"Hybrid Locomotion Research\",\n    subtitle: \"NEAT + imitation → DDPG fine-tuning\",\n    role: \"Researcher\",\n    pill: \"Research / RL\",\n    pillTone: \"research\",\n    desc:\n      \"A hybrid locomotion pipeline that bootstraps walking from motion-captured human joint angles using NEAT, then fine-tunes with DDPG for generalization in rough terrain. The main bottleneck was observation design.\",\n    longDesc: `\n## Overview\nMost reinforcement learning locomotion projects waste a huge amount of time in the early phase doing useless exploration. The agent spends forever flailing before it discovers anything that resembles walking.\n\nThis project was my attempt to fix that first part.\n\nInstead of asking an agent to learn locomotion from scratch, I built a hybrid pipeline that starts with a human example, then transfers into reinforcement learning to generalize.\n\nThe idea is simple:\n1) learn the shape of walking first (mimicry),\n2) then learn how to survive real environments (fine-tuning).\n\nThe full write-up is available here: [NEAT + DDPG Hybrid Locomotion Paper](/papers/hybrid-locomotion.pdf)\n\n## The problem I was solving\nWhen the internet goes down, the question is usually \"is this a local issue or is something bigger failing?\"\n\nLocomotion RL has a similar problem early on.\nThe agent has no clue what “movement” even means yet, so it burns time exploring actions that will never work on a real robot.\n\nHumans don’t learn like that.\nKids learn by copying. They start with examples. Then they get better through practice.\n\nSo I tried to do the same thing for a bipedal walker.\n\n## The approach\nI designed a two-stage training pipeline.\n\n### Stage 1: mimic human walking\nI took a walking video and extracted joint angles frame by frame using Mediapipe. From each frame, I computed key joint angles and created paired training examples:\n- input: joint angles at time t\n- target: joint angles at time t+1 (converted into motor control)\n\nThat conversion mattered because the environment I used (OpenAI’s BipedalWalker) doesn’t take target angles. It takes continuous motor torques in a -1 to 1 range, so I mapped joint-angle deltas into motor commands.\n\nThen I trained a policy network to imitate the human movement.\n\n### Stage 2: fine-tune in a real RL environment\nOnce I had a network that could produce walking-like actions, I used it as the actor inside DDPG and fine-tuned it directly in the simulated environment.\n\nThis let the agent start from something that looks like a gait instead of random thrashing.\n\n## Why NEAT was part of it\nInstead of locking myself into one static network shape, I used NEAT-style evolution to search for a lightweight topology that fit the mimicry task.\n\nThe goal was not “bigger network.”\nThe goal was “minimal structure that works.”\n\nI used NEAT-style mutation (adding nodes, adding connections, toggling connections, resetting weights, perturbing weights) and scored networks based on inverse training error.\n\nThe takeaway was clear.\nSimpler topologies learned cleaner and converged faster.\n\n## What happened (results)\nThere were two major outcomes.\n\n### 1) The pretrained agent started stronger\nWhen I transferred the mimicry-trained actor into DDPG, it started off with a noticeably higher average reward than a blank-slate DDPG agent trained with the same limited inputs.\n\nThat’s the core win.\nThe human example actually did what it was supposed to do.\n\n### 2) It plateaued hard\nEven though the pretrained agent started higher and plateaued higher, it still hit a ceiling and stopped improving.\n\nAt first that looked like an algorithm failure.\nIt wasn’t.\n\nIt was an input failure.\n\n## The real lesson: observation design is the ceiling\nIn both the mimicry training and the fine-tuning stage, I was only giving the agent a small slice of state.\nBasically just the four joint angles.\n\nThat means the policy is walking blind.\nNo body angle, no contact understanding, no ground relationship, no richer state.\n\nWhen I ran DDPG from scratch with more environmental inputs, it kept improving instead of plateauing.\n\nSo the pretrained policy helped early exploration, but the limited observation space capped long-term learning.\n\nThis project is the reason I’m strict now about interface design in simulation.\nThe model matters, but the observation pipeline often matters more.\n\n## What I’d do next\nThe next version is a hybrid that keeps the imitation bootstrapping but expands the state representation in a controlled way.\n\nThe hard part is that you can’t just bolt on new inputs at the end without breaking what you trained earlier.\nIf you do, you overwrite the skill you were trying to preserve.\n\nSo the next step is either:\n- evolve with the full observation space from the start, even if some channels are initially empty, or\n- introduce an intermediate step that expands the policy capacity without destroying the gait prior\n\nThat’s where this gets interesting.\n\n## What this project says about how I build\nThis wasn’t about getting a perfect walking robot.\nIt was about building a system that:\n- starts from real signal instead of random exploration\n- learns faster early\n- exposes bottlenecks clearly\n\nThe plateau wasn’t a failure. It was the point.\nIt told me exactly what mattered next.\n`.trim(),\n    href: \"/journey\",\n    embedUrl: \"/papers/hybrid-locomotion.pdf\",\n  },\n\n  {\n    slug: \"virtual-creatures\",\n    title: \"Virtual Creatures (UTMIST)\",\n    subtitle: \"Evolution + PPO + coordination\",\n    role: \"Lead Researcher\",\n    pill: \"Research / Simulation\",\n    pillTone: \"research\",\n    desc:\n      \"Research at UTMIST (University of Toronto Machine Intelligence Student Team) on evolving creature morphologies, training a universal PPO walking policy, and coordinating 2v2 soccer using grid-based planning with AlphaZero-style fine-tuning.\",\n    longDesc: `\n## Overview\nThis project was done through UTMIST, the University of Toronto Machine Intelligence Student Team.\n\nThe goal was ambitious on purpose.\nBuild a full pipeline that goes from evolving bodies to coordinated multi-agent behavior in a 2v2 soccer environment.\n\nNot just “make creatures walk.”\nMake creatures coordinate.\n\nThe full report is available here: [Virtual Creatures Project Report](/papers/virtual-creatures.pdf)\n\n## The core idea\nMost RL creature projects stop once movement works.\nBut movement is the easy part.\n\nCoordination is where things break:\n- agents can get reward without learning teamwork\n- coordination can collapse under small distribution shifts\n- policies that “work” can fail the second the environment changes\n\nSo we treated this like a full stack problem.\nMorphology, locomotion, strategy, execution.\n\n## Phase 1: evolve baseline creatures (bodies + sensors)\nWe generated creatures through a genetic algorithm inspired by Karl Sims’ classic 1994 “Virtual Creatures” work.\n\nThe goal of this phase was to evolve creatures that could move toward a waypoint reliably.\n\nThe loop looked like this:\n- selection: keep the top performers\n- pruning: remove creatures that cannot move or drift uselessly\n- mutation: change segments, joints, sensor placement, and morphology\n\nWe used a simple reward setup based on distance to the target:\n\\\\[\nR_t = \\\\frac{1}{(distance\\\\_from\\\\_target)^2}\n\\\\]\n\nThis produced a range of morphologies with different movement styles, including aggressive “launch forward” designs and more stable “stay near target” ones.\n\n## Phase 2: learn a universal walking policy (PPO)\nOnce we had bodies, the next step was to build a low-level motor control policy that generalizes across different morphologies.\n\nWe trained a universal PPO locomotion policy in MuJoCo, with multiple creature designs trained simultaneously.\nWe also used curriculum learning by gradually increasing target distances once the creatures succeeded at closer targets.\n\nThe key point.\nWe weren’t training one creature.\nWe were training a policy that could adapt.\n\nThis phase mattered because it meant movement became a reusable skill rather than a one-off solution.\n\n## Phase 3: strategy and coordination (soccer)\nThen we switched from locomotion to team play.\n\nWe set up a 2v2 soccer environment and represented the field as a grid.\nStrategy learning happened at the grid level, not the motor level.\n\nThe coordination stack looked like this:\n- learn two heatmaps with Transformers\n  - a player heatmap for positioning\n  - a ball heatmap for where to push the ball for advantage\n- initialize heatmaps using random rollouts labeled by outcome (+1 or -1)\n- fine-tune with MCTS and AlphaZero-style self-play\n\nSo this wasn’t end-to-end neural net soccer.\nIt was hierarchical:\n- a high-level planner outputs target coordinates\n- a low-level walking policy turns coordinates into movement\n\n## End-to-end pipeline (what actually ran)\nThe pipeline was:\n1) evolve creature morphologies\n2) encode them into MuJoCo-compatible XML\n3) drop them into a soccer environment\n4) run a planner to pick target coordinates\n5) execute those targets through the universal PPO motor policy\n\n## What I think is interesting here\nTwo things.\n\n### 1) Modularity without losing realism\nA lot of projects either:\n- do pure physics simulation with no strategy, or\n- do pure strategy with toy movement\n\nThis combined both.\n\nThe motor control wasn’t fake.\nThe planner wasn’t hard-coded.\nThey interfaced cleanly.\n\n### 2) Coordination becomes measurable\nInstead of guessing whether teamwork exists, we forced it into explicit representations:\n- heatmaps\n- grid advantage\n- target-based control\n\nThat made it much easier to debug.\n\n## Outcome\nWe built the full stack.\nEvolved bodies.\nLearned locomotion that generalizes.\nAdded a coordination layer.\nRan 2v2 soccer simulation with realistic physics underneath.\n\nMore importantly, it produced a platform we could keep extending, because the pieces weren’t welded together as a single black box.\n\n## What this project says about how I build\nThis is the same pattern I keep coming back to:\n- build the environment first\n- make the signals measurable\n- modularize the system so each part can improve without breaking the whole thing\n\nThat’s how you get systems that scale past demos.\n`.trim(),\n    href: \"/journey\",\n    embedUrl: \"/papers/virtual-creatures.pdf\",\n  },\n];\n\nexport function getProject(slug: string) {\n  return projects.find((p) => p.slug === slug) || null;\n}\n\n/*\n============================================================\nSCALING THE PROJECT BLOG TO 75% (like the landing page)\n============================================================\n\n1) Wrap your project blog content with a class:\n\n<div className=\"projectZoomWrap\">\n  ...your markdown / longDesc render...\n</div>\n\n2) Add CSS:\n\n.projectZoomWrap {\n  zoom: 0.75;\n}\n\n(This works in Chrome and matches the “75% zoom” feel.)\n*/\n"],"names":[],"mappings":"AAAA,uBAAuB;;;;;;;AAsBhB,MAAM,WAAsB;IACjC;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgCf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8Bf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6Bf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,YAAY;IACd;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;AAsBf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;AAkBf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,YAAY;IACd;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;AAiBf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAyGf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAqHf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;CACD;AAEM,SAAS,WAAW,IAAY;IACrC,OAAO,SAAS,IAAI,CAAC,CAAC,IAAM,EAAE,IAAI,KAAK,SAAS;AAClD,EAEA;;;;;;;;;;;;;;;;;;AAkBA"}},
    {"offset": {"line": 668, "column": 0}, "map": {"version":3,"sources":["file:///Users/andrewgordienko/Documents/andrewgordienko-website/app/projects/%5Bslug%5D/page.tsx"],"sourcesContent":["import Link from \"next/link\";\nimport { notFound } from \"next/navigation\";\n\nimport NavBar from \"@/components/NavBar\";\nimport ProjectEmbed from \"@/components/ProjectEmbed\";\nimport { getProject } from \"../data\";\n\nexport default async function ProjectPage({\n  params,\n}: {\n  params: Promise<{ slug: string }>;\n}) {\n  const { slug } = await params;\n\n  const project = getProject(slug);\n  if (!project) return notFound();\n\n  const externalWebsite =\n    project.href && project.href.startsWith(\"http\") ? project.href : null;\n\n  const websiteLabel = externalWebsite\n    ? externalWebsite.replace(/^https?:\\/\\//, \"\").replace(/\\/$/, \"\")\n    : null;\n\n  return (\n    <div className=\"container\">\n      <NavBar />\n\n      <main className=\"projectMain\">\n        <div className=\"projectShell\">\n          <div className=\"projectTop\">\n            <Link href=\"/\" className=\"projectBackLink\">\n              ← Back\n            </Link>\n          </div>\n\n          <header className=\"projectHeader\">\n            <div className=\"projectHeaderTop\">\n              <h1 className=\"projectTitle\">{project.title}</h1>\n              <div className={`pill ${pillToneClass(project.pillTone)}`}>\n                {project.pill}\n              </div>\n            </div>\n\n            <div className=\"projectMetaRow\">\n              <span className=\"projectSubtitle\">{project.subtitle}</span>\n              <span className=\"projectDot\">•</span>\n              <span className=\"projectRole\">{project.role}</span>\n            </div>\n\n            {externalWebsite ? (\n              <div className=\"projectWebsiteRow\">\n                <span className=\"projectWebsiteLabel\">Website</span>\n                <a\n                  className=\"projectWebsiteLink\"\n                  href={externalWebsite}\n                  target=\"_blank\"\n                  rel=\"noreferrer\"\n                >\n                  {websiteLabel} →\n                </a>\n              </div>\n            ) : null}\n\n            <p className=\"projectDek\">{project.desc}</p>\n\n            {project.embedUrl ? (\n              <div className=\"projectEmbedRow\">\n                <ProjectEmbed\n                  src={project.embedUrl}\n                  title={`${project.title} preview`}\n                />\n              </div>\n            ) : null}\n          </header>\n\n          <article className=\"projectArticle\">\n            <RichText content={project.longDesc} />\n\n            <div className=\"projectCtas\">\n              {!project.comingSoon && project.href !== \"#\" ? (\n                <a\n                  className=\"projectPrimaryCta\"\n                  href={project.href}\n                  target={project.href.startsWith(\"http\") ? \"_blank\" : undefined}\n                  rel={project.href.startsWith(\"http\") ? \"noreferrer\" : undefined}\n                >\n                  Open →\n                </a>\n              ) : (\n                <div className=\"projectMuted\">Coming soon →</div>\n              )}\n            </div>\n          </article>\n        </div>\n      </main>\n    </div>\n  );\n}\n\n/**\n * Lightweight markdown-ish renderer.\n * Supports:\n * - \"## Heading\" -> <h2>\n * - \"- bullet\" -> <ul><li>\n * - blank lines -> paragraph separation\n */\nfunction RichText({ content }: { content: string }) {\n  const lines = content.split(\"\\n\");\n\n  const blocks: Array<\n    | { type: \"h2\"; text: string }\n    | { type: \"p\"; text: string }\n    | { type: \"ul\"; items: string[] }\n  > = [];\n\n  let paragraphBuffer: string[] = [];\n  let listBuffer: string[] = [];\n\n  const flushParagraph = () => {\n    const text = paragraphBuffer.join(\" \").trim();\n    if (text) blocks.push({ type: \"p\", text });\n    paragraphBuffer = [];\n  };\n\n  const flushList = () => {\n    if (listBuffer.length) blocks.push({ type: \"ul\", items: listBuffer });\n    listBuffer = [];\n  };\n\n  for (const raw of lines) {\n    const line = raw.trim();\n\n    if (!line) {\n      flushList();\n      flushParagraph();\n      continue;\n    }\n\n    if (line.startsWith(\"## \")) {\n      flushList();\n      flushParagraph();\n      blocks.push({ type: \"h2\", text: line.replace(/^##\\s+/, \"\").trim() });\n      continue;\n    }\n\n    if (line.startsWith(\"- \")) {\n      flushParagraph();\n      listBuffer.push(line.replace(/^- /, \"\").trim());\n      continue;\n    }\n\n    flushList();\n    paragraphBuffer.push(line);\n  }\n\n  flushList();\n  flushParagraph();\n\n  return (\n    <>\n      {blocks.map((b, idx) => {\n        if (b.type === \"h2\") {\n          return (\n            <h2 key={idx} className=\"projectH2\">\n              {b.text}\n            </h2>\n          );\n        }\n\n        if (b.type === \"ul\") {\n          return (\n            <ul key={idx} className=\"projectUl\">\n              {b.items.map((it, j) => (\n                <li key={j}>{it}</li>\n              ))}\n            </ul>\n          );\n        }\n\n        return (\n          <p key={idx} className=\"projectP\">\n            {b.text}\n          </p>\n        );\n      })}\n    </>\n  );\n}\n\nfunction pillToneClass(tone: \"companies\" | \"simulation\" | \"research\") {\n  if (tone === \"companies\") return \"pillCompanies\";\n  if (tone === \"simulation\") return \"pillSimulation\";\n  return \"pillResearch\";\n}\n"],"names":[],"mappings":";;;;;AAAA;AACA;AAAA;AAEA;AACA;AACA;;;;;;;AAEe,eAAe,YAAY,EACxC,MAAM,EAGP;IACC,MAAM,EAAE,IAAI,EAAE,GAAG,MAAM;IAEvB,MAAM,UAAU,IAAA,qIAAU,EAAC;IAC3B,IAAI,CAAC,SAAS,OAAO,IAAA,iMAAQ;IAE7B,MAAM,kBACJ,QAAQ,IAAI,IAAI,QAAQ,IAAI,CAAC,UAAU,CAAC,UAAU,QAAQ,IAAI,GAAG;IAEnE,MAAM,eAAe,kBACjB,gBAAgB,OAAO,CAAC,gBAAgB,IAAI,OAAO,CAAC,OAAO,MAC3D;IAEJ,qBACE,8OAAC;QAAI,WAAU;;0BACb,8OAAC,gIAAM;;;;;0BAEP,8OAAC;gBAAK,WAAU;0BACd,cAAA,8OAAC;oBAAI,WAAU;;sCACb,8OAAC;4BAAI,WAAU;sCACb,cAAA,8OAAC,0LAAI;gCAAC,MAAK;gCAAI,WAAU;0CAAkB;;;;;;;;;;;sCAK7C,8OAAC;4BAAO,WAAU;;8CAChB,8OAAC;oCAAI,WAAU;;sDACb,8OAAC;4CAAG,WAAU;sDAAgB,QAAQ,KAAK;;;;;;sDAC3C,8OAAC;4CAAI,WAAW,CAAC,KAAK,EAAE,cAAc,QAAQ,QAAQ,GAAG;sDACtD,QAAQ,IAAI;;;;;;;;;;;;8CAIjB,8OAAC;oCAAI,WAAU;;sDACb,8OAAC;4CAAK,WAAU;sDAAmB,QAAQ,QAAQ;;;;;;sDACnD,8OAAC;4CAAK,WAAU;sDAAa;;;;;;sDAC7B,8OAAC;4CAAK,WAAU;sDAAe,QAAQ,IAAI;;;;;;;;;;;;gCAG5C,gCACC,8OAAC;oCAAI,WAAU;;sDACb,8OAAC;4CAAK,WAAU;sDAAsB;;;;;;sDACtC,8OAAC;4CACC,WAAU;4CACV,MAAM;4CACN,QAAO;4CACP,KAAI;;gDAEH;gDAAa;;;;;;;;;;;;2CAGhB;8CAEJ,8OAAC;oCAAE,WAAU;8CAAc,QAAQ,IAAI;;;;;;gCAEtC,QAAQ,QAAQ,iBACf,8OAAC;oCAAI,WAAU;8CACb,cAAA,8OAAC,sIAAY;wCACX,KAAK,QAAQ,QAAQ;wCACrB,OAAO,GAAG,QAAQ,KAAK,CAAC,QAAQ,CAAC;;;;;;;;;;2CAGnC;;;;;;;sCAGN,8OAAC;4BAAQ,WAAU;;8CACjB,8OAAC;oCAAS,SAAS,QAAQ,QAAQ;;;;;;8CAEnC,8OAAC;oCAAI,WAAU;8CACZ,CAAC,QAAQ,UAAU,IAAI,QAAQ,IAAI,KAAK,oBACvC,8OAAC;wCACC,WAAU;wCACV,MAAM,QAAQ,IAAI;wCAClB,QAAQ,QAAQ,IAAI,CAAC,UAAU,CAAC,UAAU,WAAW;wCACrD,KAAK,QAAQ,IAAI,CAAC,UAAU,CAAC,UAAU,eAAe;kDACvD;;;;;6DAID,8OAAC;wCAAI,WAAU;kDAAe;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAQ9C;AAEA;;;;;;CAMC,GACD,SAAS,SAAS,EAAE,OAAO,EAAuB;IAChD,MAAM,QAAQ,QAAQ,KAAK,CAAC;IAE5B,MAAM,SAIF,EAAE;IAEN,IAAI,kBAA4B,EAAE;IAClC,IAAI,aAAuB,EAAE;IAE7B,MAAM,iBAAiB;QACrB,MAAM,OAAO,gBAAgB,IAAI,CAAC,KAAK,IAAI;QAC3C,IAAI,MAAM,OAAO,IAAI,CAAC;YAAE,MAAM;YAAK;QAAK;QACxC,kBAAkB,EAAE;IACtB;IAEA,MAAM,YAAY;QAChB,IAAI,WAAW,MAAM,EAAE,OAAO,IAAI,CAAC;YAAE,MAAM;YAAM,OAAO;QAAW;QACnE,aAAa,EAAE;IACjB;IAEA,KAAK,MAAM,OAAO,MAAO;QACvB,MAAM,OAAO,IAAI,IAAI;QAErB,IAAI,CAAC,MAAM;YACT;YACA;YACA;QACF;QAEA,IAAI,KAAK,UAAU,CAAC,QAAQ;YAC1B;YACA;YACA,OAAO,IAAI,CAAC;gBAAE,MAAM;gBAAM,MAAM,KAAK,OAAO,CAAC,UAAU,IAAI,IAAI;YAAG;YAClE;QACF;QAEA,IAAI,KAAK,UAAU,CAAC,OAAO;YACzB;YACA,WAAW,IAAI,CAAC,KAAK,OAAO,CAAC,OAAO,IAAI,IAAI;YAC5C;QACF;QAEA;QACA,gBAAgB,IAAI,CAAC;IACvB;IAEA;IACA;IAEA,qBACE;kBACG,OAAO,GAAG,CAAC,CAAC,GAAG;YACd,IAAI,EAAE,IAAI,KAAK,MAAM;gBACnB,qBACE,8OAAC;oBAAa,WAAU;8BACrB,EAAE,IAAI;mBADA;;;;;YAIb;YAEA,IAAI,EAAE,IAAI,KAAK,MAAM;gBACnB,qBACE,8OAAC;oBAAa,WAAU;8BACrB,EAAE,KAAK,CAAC,GAAG,CAAC,CAAC,IAAI,kBAChB,8OAAC;sCAAY;2BAAJ;;;;;mBAFJ;;;;;YAMb;YAEA,qBACE,8OAAC;gBAAY,WAAU;0BACpB,EAAE,IAAI;eADD;;;;;QAIZ;;AAGN;AAEA,SAAS,cAAc,IAA6C;IAClE,IAAI,SAAS,aAAa,OAAO;IACjC,IAAI,SAAS,cAAc,OAAO;IAClC,OAAO;AACT"}}]
}