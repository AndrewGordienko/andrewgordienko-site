{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 13, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/components/NavBar.module.css [app-rsc] (css module)"],"sourcesContent":["__turbopack_context__.v({\n  \"brand\": \"NavBar-module__8u-qnq__brand\",\n  \"link\": \"NavBar-module__8u-qnq__link\",\n  \"nav\": \"NavBar-module__8u-qnq__nav\",\n  \"navlinks\": \"NavBar-module__8u-qnq__navlinks\",\n});\n"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA"}},
    {"offset": {"line": 23, "column": 0}, "map": {"version":3,"sources":["file:///Users/andrewgordienko/Documents/andrewgordienko-website/components/NavBar.tsx"],"sourcesContent":["import Link from \"next/link\";\nimport styles from \"./NavBar.module.css\";\n\nexport default function NavBar() {\n  return (\n    <header className={styles.nav}>\n      <Link href=\"/\" className={styles.brand}>\n        &lt;Andrew /&gt;\n      </Link>\n\n      <nav className={styles.navlinks}>\n        <Link href=\"/resume\" className={styles.link}>\n          RESUME\n        </Link>\n        <Link href=\"/contact\" className={styles.link}>\n          CONTACT\n        </Link>\n      </nav>\n    </header>\n  );\n}\n"],"names":[],"mappings":";;;;;AAAA;AACA;;;;AAEe,SAAS;IACtB,qBACE,8OAAC;QAAO,WAAW,2IAAM,CAAC,GAAG;;0BAC3B,8OAAC,0LAAI;gBAAC,MAAK;gBAAI,WAAW,2IAAM,CAAC,KAAK;0BAAE;;;;;;0BAIxC,8OAAC;gBAAI,WAAW,2IAAM,CAAC,QAAQ;;kCAC7B,8OAAC,0LAAI;wBAAC,MAAK;wBAAU,WAAW,2IAAM,CAAC,IAAI;kCAAE;;;;;;kCAG7C,8OAAC,0LAAI;wBAAC,MAAK;wBAAW,WAAW,2IAAM,CAAC,IAAI;kCAAE;;;;;;;;;;;;;;;;;;AAMtD"}},
    {"offset": {"line": 83, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/components/ProjectEmbed.module.css [app-rsc] (css module)"],"sourcesContent":["__turbopack_context__.v({\n  \"dot\": \"ProjectEmbed-module__J3EKZa__dot\",\n  \"embedFrame\": \"ProjectEmbed-module__J3EKZa__embedFrame\",\n  \"embedPdf\": \"ProjectEmbed-module__J3EKZa__embedPdf\",\n  \"embedSite\": \"ProjectEmbed-module__J3EKZa__embedSite\",\n  \"embedTopBar\": \"ProjectEmbed-module__J3EKZa__embedTopBar\",\n  \"embedViewport\": \"ProjectEmbed-module__J3EKZa__embedViewport\",\n  \"green\": \"ProjectEmbed-module__J3EKZa__green\",\n  \"red\": \"ProjectEmbed-module__J3EKZa__red\",\n  \"yellow\": \"ProjectEmbed-module__J3EKZa__yellow\",\n});\n"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA"}},
    {"offset": {"line": 98, "column": 0}, "map": {"version":3,"sources":["file:///Users/andrewgordienko/Documents/andrewgordienko-website/components/ProjectEmbed.tsx"],"sourcesContent":["import styles from \"./ProjectEmbed.module.css\";\nimport { useMemo } from \"react\";\n\nexport default function ProjectEmbed({\n  src,\n  title,\n}: {\n  src: string;\n  title?: string;\n}) {\n  const isPdf = src.toLowerCase().includes(\".pdf\");\n\n  const iframeSrc = useMemo(() => {\n    if (!isPdf) return src;\n\n    const base = src.split(\"#\")[0];\n\n    return `${base}#toolbar=0&navpanes=0&scrollbar=1`;\n  }, [src, isPdf]);\n\n  return (\n    <div className={styles.embedFrame}>\n      <div className={styles.embedTopBar}>\n        <span className={`${styles.dot} ${styles.red}`} />\n        <span className={`${styles.dot} ${styles.yellow}`} />\n        <span className={`${styles.dot} ${styles.green}`} />\n      </div>\n\n      <div className={styles.embedViewport}>\n        <iframe\n          className={isPdf ? styles.embedPdf : styles.embedSite}\n          src={iframeSrc}\n          title={title ?? (isPdf ? \"PDF preview\" : \"Project preview\")}\n          loading=\"lazy\"\n          scrolling=\"auto\"\n        />\n      </div>\n    </div>\n  );\n}\n"],"names":[],"mappings":";;;;;AAAA;AACA;;;;AAEe,SAAS,aAAa,EACnC,GAAG,EACH,KAAK,EAIN;IACC,MAAM,QAAQ,IAAI,WAAW,GAAG,QAAQ,CAAC;IAEzC,MAAM,YAAY,IAAA,gNAAO,EAAC;QACxB,IAAI,CAAC,OAAO,OAAO;QAEnB,MAAM,OAAO,IAAI,KAAK,CAAC,IAAI,CAAC,EAAE;QAE9B,OAAO,GAAG,KAAK,iCAAiC,CAAC;IACnD,GAAG;QAAC;QAAK;KAAM;IAEf,qBACE,8OAAC;QAAI,WAAW,iJAAM,CAAC,UAAU;;0BAC/B,8OAAC;gBAAI,WAAW,iJAAM,CAAC,WAAW;;kCAChC,8OAAC;wBAAK,WAAW,GAAG,iJAAM,CAAC,GAAG,CAAC,CAAC,EAAE,iJAAM,CAAC,GAAG,EAAE;;;;;;kCAC9C,8OAAC;wBAAK,WAAW,GAAG,iJAAM,CAAC,GAAG,CAAC,CAAC,EAAE,iJAAM,CAAC,MAAM,EAAE;;;;;;kCACjD,8OAAC;wBAAK,WAAW,GAAG,iJAAM,CAAC,GAAG,CAAC,CAAC,EAAE,iJAAM,CAAC,KAAK,EAAE;;;;;;;;;;;;0BAGlD,8OAAC;gBAAI,WAAW,iJAAM,CAAC,aAAa;0BAClC,cAAA,8OAAC;oBACC,WAAW,QAAQ,iJAAM,CAAC,QAAQ,GAAG,iJAAM,CAAC,SAAS;oBACrD,KAAK;oBACL,OAAO,SAAS,CAAC,QAAQ,gBAAgB,iBAAiB;oBAC1D,SAAQ;oBACR,WAAU;;;;;;;;;;;;;;;;;AAKpB"}},
    {"offset": {"line": 180, "column": 0}, "map": {"version":3,"sources":["file:///Users/andrewgordienko/Documents/andrewgordienko-website/app/projects/data.ts"],"sourcesContent":["// app/projects/data.ts\n\nexport type PillTone = \"companies\" | \"simulation\" | \"research\";\n\nexport type Project = {\n  slug: string;\n  title: string;\n  subtitle: string;\n  role: string;\n\n  pill: string;\n  pillTone: PillTone;\n\n  desc: string;\n  longDesc: string;\n\n  href: string; // external site or internal route\n  embedUrl?: string; // external iframe preview (if allowed)\n\n  comingSoon?: boolean;\n};\n\nexport const projects: Project[] = [\n  {\n    slug: \"outagehub\",\n    title: \"OutageHub\",\n    subtitle: \"CanadianPowerOutages.ca\",\n    role: \"Founder and CEO\",\n    pill: \"Enterprise / Infrastructure\",\n    pillTone: \"companies\",\n    desc:\n      \"A real-time power outage map and API for Canada. Aggregation, normalization, and delivery of outage data with a focus on reliability and speed.\",\n    longDesc: `\n## The problem\nWhen the internet goes down, it is surprisingly hard to answer a simple question: is this a local network issue, or is the power out?\n\nFor telecom teams, this matters. Sending trucks is expensive, slow, and often the wrong first move if you do not have good situational awareness. Customers feel the delay, operations waste money, and everyone ends up working from guesses.\n\n## How it started\nOutageHub began after we were approached to build a lightweight way to verify power outages in an area. The goal was operational: help support and field teams separate “internet is down” from “power is out” quickly, so decisions get made with real information instead of assumptions.\n\n## The first prototype\nI built an early prototype in Python to prove the concept and map the scope. It worked well enough to show the value immediately, but it also made the real challenge obvious:\n\nIf this is going to matter during live outage conditions, it needs to be reliable.\n\nThat does not just mean “the site loads.” It means the data model needs to be consistent, the update path needs to hold up, and the UI needs to stay usable when people actually need it.\n\n## Turning it into infrastructure\nOnce the scope was clear, I brought in a few friends and we started turning it into a real system.\n- ingestion across multiple sources\n- normalization into one consistent model\n- reliability under live conditions\n- a public map plus an API teams can integrate directly\n\nThe hard part is not the map. The hard part is taking messy, incomplete, inconsistent outage information and making it usable in real time.\n\n## Validation and real-world conversations\nSince then, we have spoken with utilities, charities, and multiple levels of Canadian government to validate usefulness, test accuracy, and understand how this fits into real operations.\n\nA big part of the work is making sure this is not “cool tech.” It needs to be a tool people trust when the situation is messy and high-pressure.\n\n## Where it is now\nRight now, the focus is reliability and validation. The goal is simple: when outages are happening, the system needs to hold up and stay useful.\n`.trim(),\n    href: \"https://canadianpoweroutages.ca\",\n    embedUrl: \"https://canadianpoweroutages.ca\",\n  },\n\n  {\n    slug: \"gnk-software\",\n    title: \"G&K Software\",\n    subtitle: \"Modernization contracts\",\n    role: \"Head of Sales\",\n    pill: \"Enterprise / Delivery\",\n    pillTone: \"companies\",\n    desc:\n      \"We help teams modernize legacy systems through carve-outs, integration layers, data tooling, and testing support alongside larger programs.\",\n    longDesc: `\n## What G&K does\nG&K Software is a small senior delivery team focused on modernization work that needs precision.\n\nA lot of modernization programs fail in predictable ways. The problem is not motivation or budget. It is delivery detail: unclear boundaries, integration pain, weak testing scaffolding, or data work that becomes a permanent blocker.\n\nWe focus on the work that is narrow, technical, and high-impact.\n\n## The kind of work we take on\nModernization is broad, but the parts that stall programs are usually the same:\n- service carve-outs and boundary extraction\n- integration layers and interface stabilization\n- downstream data tooling and validation pipelines\n- testing support that makes a larger program safer to ship\n\nThe goal is always the same: unblock delivery and reduce risk without turning the work into a multi-year rewrite.\n\n## Why this exists\nMost large transformation programs are run inside big teams, but the bottlenecks tend to form around specific pieces of work that need strong execution and fast turnaround.\n\nG&K is built to take those pieces, own them end-to-end, and deliver cleanly.\n\n## My role\nI run sales and early pipeline. That means:\n- outreach and relationship building\n- scoping and qualification\n- translating real pain into a small first engagement\n- keeping the conversation grounded in “what can we ship” instead of vague modernization language\n\nThe objective is straightforward: land the first contracts, deliver well, and expand from there.\n`.trim(),\n    href: \"https://gnk.software\",\n    embedUrl: \"https://gnk.software\",\n  },\n\n  {\n    slug: \"do-better-foundation\",\n    title: \"Do Better Foundation\",\n    subtitle: \"dobetterfoundation.com\",\n    role: \"Cofounder\",\n    pill: \"Enterprise / Policy\",\n    pillTone: \"companies\",\n    desc:\n      \"A research and tooling effort to find gaps in government policy and execution, starting with construction delays, using LLMs to surface patterns and root causes.\",\n    longDesc: `\n## The focus\nDo Better Foundation is about execution.\n\nA lot of public systems fail in predictable ways, but the evidence is scattered across reports, timelines, procurement documents, and fragmented accountability. The signal is there, but it is hard to see.\n\nThe goal is to build research and tooling that turns “everyone knows this is broken” into something measurable and explainable.\n\n## Why construction delays\nConstruction delays are one of the clearest examples of repeated failure patterns:\n- timelines slip in similar ways across projects\n- bottlenecks repeat, but the explanations are inconsistent\n- the cost of delay is real and compounding\n\nIt is a space with enough public data to analyze, and enough operational complexity that you cannot solve it with a single spreadsheet.\n\n## What we are building\nThe core idea is simple: pull the evidence together, then surface patterns.\n- collect documents and structured sources\n- normalize what “delay” actually means across contexts\n- extract recurring root causes\n- generate outputs that are actionable and explainable\n\nLLMs help, but only as part of a real system. The goal is not text generation. The goal is clarity: what is failing, where, and why.\n\n## Where it is now\nWe are building the foundations and validating what is actually useful to the people closest to the problem.\n\nThe bar is high. If this is going to matter, it needs to produce answers that are practical and defensible, not just “interesting analysis.”\n`.trim(),\n    href: \"#\",\n    comingSoon: true,\n  },\n\n  {\n    slug: \"bike-rebalance\",\n    title: \"Bike Rebalance Simulator\",\n    subtitle: \"Toronto Bike Share optimization\",\n    role: \"Builder\",\n    pill: \"Simulation / Optimization\",\n    pillTone: \"simulation\",\n    desc:\n      \"A simulation and optimization project to forecast station shortages and generate rebalance plans, including event-driven demand signals.\",\n    longDesc: `\nBike Rebalance Simulator\n\nToronto Bike share has a simple failure mode that shows up every single day: the wrong stations go empty or full at the wrong times. When a station hits zero bikes, riders can’t start trips. When a station hits zero docks, riders can’t end trips, and the whole network starts to degrade. Those failures aren’t random. They follow patterns that come from commuting flow, land use, and station “roles” across the city.\n\nI built this project because most bike share work stops too early. It’s easy to make dashboards and post-hoc charts. It’s much harder to answer the operational question that actually matters: given a specific day, what should an operator do to prevent stations from failing before it happens?\n\nThis simulator is meant to be a full loop from data to action. It takes real trip records, simulates station inventory through time, and then tries different planning strategies to reduce shortages. The focus isn’t just on prediction — it’s on building a system that can propose interventions, and then verify that those interventions actually improve outcomes when replayed against real trip flow.\n\n## Modeling inventory as a day simulation\n\nAt the base of the system is a station-state simulator. Every trip is treated as two events: a departure that removes a bike from the start station, and an arrival that adds a bike to the end station (bounded by station capacity). With that, you can simulate station inventory forward minute by minute or in fixed time buckets.\n\nI chose fixed buckets, typically 15 minutes, because they’re a good balance between realism and compute. The simulator reads all trips for a given date, converts them into time-stamped events, and updates the station bike counts as time moves forward. The output is a full day replay: bikes and empty docks at every station for every time bucket. That baseline replay is important because it makes the rest of the project measurable. You can’t improve a system you can’t reliably reproduce.\n\nThe simulator supports a simple default midnight initialization, where stations start at a uniform fill ratio of their capacity. But it also supports a stronger mode where the midnight bike distribution is explicitly provided. That matters because in real operations, the day’s outcome is heavily influenced by where bikes start at midnight — not just what trucks do later.\n\n## Learning station “behavior fingerprints” from trip history\n\nOnce the baseline simulation worked, the next piece was understanding station behavior. Stations aren’t just points on a map; they act differently depending on their context. A station in a residential neighborhood often drains bikes in the morning and fills back up in the evening. A station downtown often does the opposite. Some stations have nightlife patterns where late-night departures dominate. These patterns are stable enough that you can treat them like station identities.\n\nTo capture that, I built hourly profiles for every station using trip logs. For each station, I count how many trips depart from it during each hour of the day, and how many trips arrive to it during each hour. That produces two 24-dimensional histograms per station. Then, instead of clustering on raw counts (which would mostly cluster by volume), I normalize each station into distributions. The point is to capture the shape of activity, not how busy the station is.\n\nBy concatenating the normalized departure distribution and normalized arrival distribution, each station becomes a 48-dimensional signature vector. It’s a compact fingerprint of how that station behaves across a full day.\n\n## Clustering stations into operationally meaningful groups\n\nWith signatures built, I cluster stations using KMeans. This step takes hundreds of individual station patterns and compresses them into a small set of station archetypes. The goal isn’t academic clustering for its own sake — it’s to create a tool that makes the system more controllable.\n\nOnce the clusters exist, you can start making decisions that look like real operations. A shortage at a residential AM-outbound station is not the same as a shortage at a downtown AM-inbound station. The response timing and urgency are different. The clustering step gives the planner a way to treat station types differently without hardcoding a giant list of exceptions.\n\nTo keep clusters interpretable, I also generate simple summaries of each cluster by measuring how much mass exists in “night departures,” “AM departures,” “PM departures,” and so on. That makes it possible to attach labels later like residential outbound, downtown inbound, nightlife-heavy, or commuter-balanced.\n\n## Midnight optimization: fixing the starting conditions\n\nBefore even planning trucks, I built a midnight optimizer. This handles a surprisingly large amount of the problem because a bad starting distribution guarantees failures later no matter how smart the truck plan is. If you start the day with bikes in the wrong places, you spend the entire morning playing catch-up.\n\nThe midnight optimizer takes a fixed number of bikes in the whole system and decides how they should be allocated across stations at 00:00. It works by simulating each station’s inventory trajectory over the day using bucketized net flow (arrivals minus departures). Then it scores the station based on time spent too empty or too full relative to thresholds, like “below 10% full” or “above 90% full.”\n\nFrom there, it runs a greedy 1-bike swap algorithm. In each step it finds the station that would benefit most from receiving one bike, and the station that would be least harmed (or most improved) by donating one bike, and moves a single bike. Because each station’s trajectory depends only on its own starting inventory and its own flow series, the optimizer can update costs efficiently without recomputing the entire day for every station on every move.\n\nThe result is a midnight distribution that reduces downstream failures across the day without using trucks at all. It’s a clean example of how modeling the system properly often matters more than adding complexity.\n\n## Whole-day truck planning with a global cost objective\n\nTruck moves are the active control layer. The goal isn’t to greedily “fix the worst station right now,” because that tends to waste moves. The real objective is global: choose a small number of moves throughout the service window that reduce overall system failure across the day.\n\nThe planner represents a truck move as a timed action: move N bikes from a source station to a sink station at a specific time bucket. It enforces realistic constraints like a max truck capacity per move, donor stations not being drained below a minimum, and receivers not being filled beyond capacity. There’s also an optional travel realism constraint using station lat/lon, including distance penalties and hard rejection of overly long transfers.\n\nThe planning algorithm is greedy but global. At each step, it evaluates a set of candidate moves and selects the one that produces the largest reduction in total system cost. The cost is computed from the simulation series, and crucially, when evaluating a candidate move at time b0, only two stations are affected from that time onward. That lets the planner recompute only the cost of the source and sink rather than resimulating the entire city for every candidate.\n\nThis makes it feasible to plan across hundreds of stations with a small move budget, while still optimizing for total network health rather than one local metric.\n\n## The real upgrade: planning for buffer, not thresholds\n\nThreshold penalties like “avoid empty” and “avoid full” are useful, but they miss the real operational intuition. Stations don’t fail because they are slightly low or slightly high. They fail when they can’t absorb what’s about to happen next.\n\nSo I upgraded the objective to be time-aware and demand-aware using a lookahead window. Instead of only penalizing stations for being near-empty or near-full, I compute upcoming departures and arrivals over the next few hours. If a station has an outbound pickup wave coming, it needs bike buffer ahead of time. If it’s about to receive a wave of arrivals, it needs dock buffer ahead of time.\n\nThat changes the planner from “react to being empty” into “pre-position inventory to prevent emptiness.” It’s closer to how real dispatch works: the best move is often the one you make before the station actually breaks.\n\n## Making the planner cluster-aware\n\nOnce clusters exist, the buffer objective can be scaled by station type and time of day. A residential station in the morning is extremely sensitive to bike availability. A downtown station in the morning is extremely sensitive to dock availability. A nightlife cluster is sensitive late at night. By applying mild multipliers based on (cluster_id, hour), the planner stops treating the city as uniform.\n\nThat makes the results more stable and more realistic, and it opens the door to tuning with operational feedback. The cluster system becomes a compact way to encode behavior patterns without hardcoding a station-by-station rule list.\n\n## Replay mode: verifying the plan actually works\n\nPlanning is only half the job. A plan that looks good on paper but can’t be verified is worthless.\n\nAfter generating a schedule of TruckMove actions, I replay them through the simulator on the same trip day. Planned moves are applied at their exact times and clamped to feasibility. Then the same station-state outputs are regenerated. This makes evaluation clean: same trips, same day, same baseline — only the intervention policy changes.\n\nThat is what turns the project from analysis into a true system. You can compare baseline and planned outcomes in a way that’s honest, repeatable, and measurable.\n\n## Where this goes next\n\nThis simulator is already useful as a modeling and planning sandbox, but the most interesting next step is adding event-driven demand signals. Baseline commuter patterns are predictable, but large events create spikes that break normal assumptions. Incorporating concerts, games, and other scheduled events would let the planner pre-position inventory for abnormal flow.\n\nThe other next step is turning planner outputs into operator-facing signals instead of raw CSVs. The long-term goal is not “generate data.” The goal is to surface the right interventions, explain why they help, and make it easy to validate outcomes.\n\nThat’s the whole theme of the project: take messy real-world movement, make it measurable, and then build systems that can actually act on it.\n`.trim(),\n\n    href: \"http://155.138.143.63/rebalance/\",\n    embedUrl: \"http://155.138.143.63/rebalance/\",\n  },\n\n  {\n    slug: \"f1-simulator\",\n    title: \"F1 Simulator\",\n    subtitle: \"In progress\",\n    role: \"Builder\",\n    pill: \"Simulation / Motorsports\",\n    pillTone: \"simulation\",\n    desc:\n      \"A racing sim playground to explore vehicle dynamics, overtakes, track geometry, and performance engineering workflows.\",\n    longDesc: `\n## Why I started it\nI wanted a sandbox where I could explore racing engineering problems without relying on black-box tooling.\n\nThe goal is not “make a game.” The goal is to create an environment where you can build intuition, test ideas, and iterate quickly.\n\n## What it covers\nThe simulator focuses on the parts of racing that are interesting from a systems perspective:\n- vehicle dynamics and control stability\n- track geometry, tangents, and constraints\n- overtakes and multi-agent interactions\n- performance tooling and visualization workflows\n\n## The point\nThis is an engineering playground. It lets me treat racing like an applied optimization and control problem, with just enough realism to make the tradeoffs meaningful.\n\n## Status\nIn progress. I’m building it as a long-running project with the goal of reaching “useful tool” quality, not just a demo.\n`.trim(),\n    href: \"#\",\n    comingSoon: true,\n  },\n\n  {\n    slug: \"chess-engine\",\n    title: \"Chess Engine\",\n    subtitle: \"In progress\",\n    role: \"Builder\",\n    pill: \"Simulation / Games\",\n    pillTone: \"simulation\",\n    desc:\n      \"A chess engine and interactive sandbox you can play with in-browser. Lightweight, fast iteration, and a clean analysis UI.\",\n    longDesc: `\n## The idea\nChess is one of the best environments for building systems that have to reason, search, and explain themselves.\n\nMost chess engines are impressive, but they are not always approachable. I wanted something fast to iterate on, and easy to inspect.\n\n## What I’m building\nA lightweight chess engine paired with an interactive UI.\n- search + evaluation loop\n- clean analysis view for lines and alternatives\n- a setup that makes it easy to test new ideas quickly\n\n## The goal\nNot just to play chess, but to make the engine’s reasoning visible.\n\n## Status\nIn progress. The focus is keeping the engine simple, fast, and hackable while still producing useful analysis.\n`.trim(),\n    href: \"http://155.138.143.63/hudson64/\",\n    embedUrl: \"http://155.138.143.63/hudson64/\",\n  },\n\n  {\n    slug: \"hybrid-locomotion\",\n    title: \"Hybrid Locomotion Research\",\n    subtitle: \"NEAT + imitation → DDPG fine-tuning\",\n    role: \"Researcher\",\n    pill: \"Research / RL\",\n    pillTone: \"research\",\n    desc:\n      \"A hybrid locomotion pipeline that bootstraps walking from motion-captured human joint angles using NEAT, then fine-tunes with DDPG for generalization in rough terrain. The main bottleneck was observation design.\",\n    longDesc: `\n## Overview\nMost reinforcement learning locomotion projects waste a huge amount of time in the early phase doing useless exploration. The agent spends forever flailing before it discovers anything that resembles walking.\n\nThis project was my attempt to fix that first part.\n\nInstead of asking an agent to learn locomotion from scratch, I built a hybrid pipeline that starts with a human example, then transfers into reinforcement learning to generalize.\n\nThe idea is simple:\n1) learn the shape of walking first (mimicry),\n2) then learn how to survive real environments (fine-tuning).\n\n## The problem I was solving\nWhen the internet goes down, the question is usually \"is this a local issue or is something bigger failing?\"\n\nLocomotion RL has a similar problem early on.\nThe agent has no clue what “movement” even means yet, so it burns time exploring actions that will never work on a real robot.\n\nHumans don’t learn like that.\nKids learn by copying. They start with examples. Then they get better through practice.\n\nSo I tried to do the same thing for a bipedal walker.\n\n## The approach\nI designed a two-stage training pipeline.\n\n Stage 1: mimic human walking\nI took a walking video and extracted joint angles frame by frame using Mediapipe. From each frame, I computed key joint angles and created paired training examples:\n- input: joint angles at time t\n- target: joint angles at time t+1 (converted into motor control)\n\nThat conversion mattered because the environment I used (OpenAI’s BipedalWalker) doesn’t take target angles. It takes continuous motor torques in a -1 to 1 range, so I mapped joint-angle deltas into motor commands.\n\nThen I trained a policy network to imitate the human movement.\n\n Stage 2: fine-tune in a real RL environment\nOnce I had a network that could produce walking-like actions, I used it as the actor inside DDPG and fine-tuned it directly in the simulated environment.\n\nThis let the agent start from something that looks like a gait instead of random thrashing.\n\n## Why NEAT was part of it\nInstead of locking myself into one static network shape, I used NEAT-style evolution to search for a lightweight topology that fit the mimicry task.\n\nThe goal was not “bigger network.”\nThe goal was “minimal structure that works.”\n\nI used NEAT-style mutation (adding nodes, adding connections, toggling connections, resetting weights, perturbing weights) and scored networks based on inverse training error.\n\nThe takeaway was clear.\nSimpler topologies learned cleaner and converged faster.\n\n## What happened (results)\nThere were two major outcomes.\n\n 1) The pretrained agent started stronger\nWhen I transferred the mimicry-trained actor into DDPG, it started off with a noticeably higher average reward than a blank-slate DDPG agent trained with the same limited inputs.\n\nThat’s the core win.\nThe human example actually did what it was supposed to do.\n\n 2) It plateaued hard\nEven though the pretrained agent started higher and plateaued higher, it still hit a ceiling and stopped improving.\n\nAt first that looked like an algorithm failure.\nIt wasn’t.\n\nIt was an input failure.\n\n## The real lesson: observation design is the ceiling\nIn both the mimicry training and the fine-tuning stage, I was only giving the agent a small slice of state.\nBasically just the four joint angles.\n\nThat means the policy is walking blind.\nNo body angle, no contact understanding, no ground relationship, no richer state.\n\nWhen I ran DDPG from scratch with more environmental inputs, it kept improving instead of plateauing.\n\nSo the pretrained policy helped early exploration, but the limited observation space capped long-term learning.\n\nThis project is the reason I’m strict now about interface design in simulation.\nThe model matters, but the observation pipeline often matters more.\n\n## What I’d do next\nThe next version is a hybrid that keeps the imitation bootstrapping but expands the state representation in a controlled way.\n\nThe hard part is that you can’t just bolt on new inputs at the end without breaking what you trained earlier.\nIf you do, you overwrite the skill you were trying to preserve.\n\nSo the next step is either:\n- evolve with the full observation space from the start, even if some channels are initially empty, or\n- introduce an intermediate step that expands the policy capacity without destroying the gait prior\n\nThat’s where this gets interesting.\n\n`.trim(),\n    href: \"/journey\",\n    embedUrl: \"/papers/hybrid-locomotion.pdf\",\n  },\n\n  {\n    slug: \"virtual-creatures\",\n    title: \"Virtual Creatures (UTMIST)\",\n    subtitle: \"Evolution + PPO + coordination\",\n    role: \"Lead Researcher\",\n    pill: \"Research / Simulation\",\n    pillTone: \"research\",\n    desc:\n      \"Research at UTMIST (University of Toronto Machine Intelligence Student Team) on evolving creature morphologies, training a universal PPO walking policy, and coordinating 2v2 soccer using grid-based planning with AlphaZero-style fine-tuning.\",\n    longDesc: `\n## Overview\nThis project was done through UTMIST, the University of Toronto Machine Intelligence Student Team.\n\nThe goal was ambitious on purpose.\nBuild a full pipeline that goes from evolving bodies to coordinated multi-agent behavior in a 2v2 soccer environment.\n\nNot just “make creatures walk.”\nMake creatures coordinate.\n\n## The core idea\nMost RL creature projects stop once movement works.\nBut movement is the easy part.\n\nCoordination is where things break:\n- agents can get reward without learning teamwork\n- coordination can collapse under small distribution shifts\n- policies that “work” can fail the second the environment changes\n\nSo we treated this like a full stack problem.\nMorphology, locomotion, strategy, execution.\n\n## Phase 1: evolve baseline creatures (bodies + sensors)\nWe generated creatures through a genetic algorithm inspired by Karl Sims’ classic 1994 “Virtual Creatures” work.\n\nThe goal of this phase was to evolve creatures that could move toward a waypoint reliably.\n\nThe loop looked like this:\n- selection: keep the top performers\n- pruning: remove creatures that cannot move or drift uselessly\n- mutation: change segments, joints, sensor placement, and morphology\n\nWe used a simple reward setup based on distance to the target:\n\\\\[\nR_t = \\\\frac{1}{(distance\\\\_from\\\\_target)^2}\n\\\\]\n\nThis produced a range of morphologies with different movement styles, including aggressive “launch forward” designs and more stable “stay near target” ones.\n\n## Phase 2: learn a universal walking policy (PPO)\nOnce we had bodies, the next step was to build a low-level motor control policy that generalizes across different morphologies.\n\nWe trained a universal PPO locomotion policy in MuJoCo, with multiple creature designs trained simultaneously.\nWe also used curriculum learning by gradually increasing target distances once the creatures succeeded at closer targets.\n\nThe key point.\nWe weren’t training one creature.\nWe were training a policy that could adapt.\n\nThis phase mattered because it meant movement became a reusable skill rather than a one-off solution.\n\n## Phase 3: strategy and coordination (soccer)\nThen we switched from locomotion to team play.\n\nWe set up a 2v2 soccer environment and represented the field as a grid.\nStrategy learning happened at the grid level, not the motor level.\n\nThe coordination stack looked like this:\n- learn two heatmaps with Transformers\n  - a player heatmap for positioning\n  - a ball heatmap for where to push the ball for advantage\n- initialize heatmaps using random rollouts labeled by outcome (+1 or -1)\n- fine-tune with MCTS and AlphaZero-style self-play\n\nSo this wasn’t end-to-end neural net soccer.\nIt was hierarchical:\n- a high-level planner outputs target coordinates\n- a low-level walking policy turns coordinates into movement\n\n## End-to-end pipeline (what actually ran)\nThe pipeline was:\n1) evolve creature morphologies\n2) encode them into MuJoCo-compatible XML\n3) drop them into a soccer environment\n4) run a planner to pick target coordinates\n5) execute those targets through the universal PPO motor policy\n\n## What I think is interesting here\nTwo things.\n\n 1) Modularity without losing realism\nA lot of projects either:\n- do pure physics simulation with no strategy, or\n- do pure strategy with toy movement\n\nThis combined both.\n\nThe motor control wasn’t fake.\nThe planner wasn’t hard-coded.\nThey interfaced cleanly.\n\n 2) Coordination becomes measurable\nInstead of guessing whether teamwork exists, we forced it into explicit representations:\n- heatmaps\n- grid advantage\n- target-based control\n\nThat made it much easier to debug.\n\n## Outcome\nWe built the full stack.\nEvolved bodies.\nLearned locomotion that generalizes.\nAdded a coordination layer.\nRan 2v2 soccer simulation with realistic physics underneath.\n\nMore importantly, it produced a platform we could keep extending, because the pieces weren’t welded together as a single black box.\n\n`.trim(),\n    href: \"/journey\",\n    embedUrl: \"/papers/virtual-creatures.pdf\",\n  },\n];\n\nexport function getProject(slug: string) {\n  return projects.find((p) => p.slug === slug) || null;\n}\n\n/*\n============================================================\nSCALING THE PROJECT BLOG TO 75% (like the landing page)\n============================================================\n\n1) Wrap your project blog content with a class:\n\n<div className=\"projectZoomWrap\">\n  ...your markdown / longDesc render...\n</div>\n\n2) Add CSS:\n\n.projectZoomWrap {\n  zoom: 0.75;\n}\n\n(This works in Chrome and matches the “75% zoom” feel.)\n*/\n"],"names":[],"mappings":"AAAA,uBAAuB;;;;;;;AAsBhB,MAAM,WAAsB;IACjC;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgCf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8Bf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6Bf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,YAAY;IACd;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkFf,CAAC,CAAC,IAAI;QAEF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;AAkBf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,YAAY;IACd;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;AAiBf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8Ff,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;IAEA;QACE,MAAM;QACN,OAAO;QACP,UAAU;QACV,MAAM;QACN,MAAM;QACN,UAAU;QACV,MACE;QACF,UAAU,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4Gf,CAAC,CAAC,IAAI;QACF,MAAM;QACN,UAAU;IACZ;CACD;AAEM,SAAS,WAAW,IAAY;IACrC,OAAO,SAAS,IAAI,CAAC,CAAC,IAAM,EAAE,IAAI,KAAK,SAAS;AAClD,EAEA;;;;;;;;;;;;;;;;;;AAkBA"}},
    {"offset": {"line": 719, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/app/projects/[slug]/ProjectPage.module.css [app-rsc] (css module)"],"sourcesContent":["__turbopack_context__.v({\n  \"article\": \"ProjectPage-module__wKwtVq__article\",\n  \"backLink\": \"ProjectPage-module__wKwtVq__backLink\",\n  \"btn\": \"ProjectPage-module__wKwtVq__btn\",\n  \"btnPrimary\": \"ProjectPage-module__wKwtVq__btnPrimary\",\n  \"ctas\": \"ProjectPage-module__wKwtVq__ctas\",\n  \"dek\": \"ProjectPage-module__wKwtVq__dek\",\n  \"dot\": \"ProjectPage-module__wKwtVq__dot\",\n  \"embedIframe\": \"ProjectPage-module__wKwtVq__embedIframe\",\n  \"embedRow\": \"ProjectPage-module__wKwtVq__embedRow\",\n  \"embedViewport\": \"ProjectPage-module__wKwtVq__embedViewport\",\n  \"h2\": \"ProjectPage-module__wKwtVq__h2\",\n  \"header\": \"ProjectPage-module__wKwtVq__header\",\n  \"headerTop\": \"ProjectPage-module__wKwtVq__headerTop\",\n  \"main\": \"ProjectPage-module__wKwtVq__main\",\n  \"metaRow\": \"ProjectPage-module__wKwtVq__metaRow\",\n  \"muted\": \"ProjectPage-module__wKwtVq__muted\",\n  \"p\": \"ProjectPage-module__wKwtVq__p\",\n  \"page\": \"ProjectPage-module__wKwtVq__page\",\n  \"pdfActions\": \"ProjectPage-module__wKwtVq__pdfActions\",\n  \"pill\": \"ProjectPage-module__wKwtVq__pill\",\n  \"pillCompanies\": \"ProjectPage-module__wKwtVq__pillCompanies\",\n  \"pillResearch\": \"ProjectPage-module__wKwtVq__pillResearch\",\n  \"pillSimulation\": \"ProjectPage-module__wKwtVq__pillSimulation\",\n  \"primaryCta\": \"ProjectPage-module__wKwtVq__primaryCta\",\n  \"role\": \"ProjectPage-module__wKwtVq__role\",\n  \"shell\": \"ProjectPage-module__wKwtVq__shell\",\n  \"subtitle\": \"ProjectPage-module__wKwtVq__subtitle\",\n  \"title\": \"ProjectPage-module__wKwtVq__title\",\n  \"top\": \"ProjectPage-module__wKwtVq__top\",\n  \"ul\": \"ProjectPage-module__wKwtVq__ul\",\n  \"websiteLabel\": \"ProjectPage-module__wKwtVq__websiteLabel\",\n  \"websiteLink\": \"ProjectPage-module__wKwtVq__websiteLink\",\n  \"websiteRow\": \"ProjectPage-module__wKwtVq__websiteRow\",\n});\n"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA"}},
    {"offset": {"line": 758, "column": 0}, "map": {"version":3,"sources":["file:///Users/andrewgordienko/Documents/andrewgordienko-website/app/projects/%5Bslug%5D/page.tsx"],"sourcesContent":["import Link from \"next/link\";\nimport { notFound } from \"next/navigation\";\n\nimport NavBar from \"@/components/NavBar\";\nimport ProjectEmbed from \"@/components/ProjectEmbed\";\nimport { getProject } from \"../data\";\n\nimport styles from \"./ProjectPage.module.css\";\n\nexport default async function ProjectPage({\n  params,\n}: {\n  params: Promise<{ slug: string }>;\n}) {\n  const { slug } = await params;\n\n  const project = getProject(slug);\n  if (!project) return notFound();\n\n  const externalWebsite =\n    project.href && project.href.startsWith(\"http\") ? project.href : null;\n\n  const websiteLabel = externalWebsite\n    ? externalWebsite.replace(/^https?:\\/\\//, \"\").replace(/\\/$/, \"\")\n    : null;\n\n  const isPdf = project.embedUrl\n    ? project.embedUrl.toLowerCase().endsWith(\".pdf\")\n    : false;\n\n  const pdfHref = isPdf ? project.embedUrl! : null;\n\n  return (\n    <div className={styles.page}>\n      <NavBar />\n\n      <main className={styles.main}>\n        <div className={styles.shell}>\n          <div className={styles.top}>\n            <Link href=\"/\" className={styles.backLink}>\n              ← Back\n            </Link>\n          </div>\n\n          <header className={styles.header}>\n            <div className={styles.headerTop}>\n              <h1 className={styles.title}>{project.title}</h1>\n\n              <div\n                className={`${styles.pill} ${pillToneClass(\n                  project.pillTone,\n                  styles\n                )}`}\n              >\n                {project.pill}\n              </div>\n            </div>\n\n            <div className={styles.metaRow}>\n              <span className={styles.subtitle}>{project.subtitle}</span>\n              <span className={styles.dot}>•</span>\n              <span className={styles.role}>{project.role}</span>\n            </div>\n\n            {externalWebsite ? (\n              <div className={styles.websiteRow}>\n                <span className={styles.websiteLabel}>Website</span>\n                <a\n                  className={styles.websiteLink}\n                  href={externalWebsite}\n                  target=\"_blank\"\n                  rel=\"noreferrer\"\n                >\n                  {websiteLabel} →\n                </a>\n              </div>\n            ) : null}\n\n            <p className={styles.dek}>{project.desc}</p>\n\n            {/* =========================\n               PDF buttons (Resume-style)\n               ========================= */}\n            {pdfHref ? (\n              <div className={styles.pdfActions}>\n                <a\n                  className={styles.btnPrimary}\n                  href={pdfHref}\n                  target=\"_blank\"\n                  rel=\"noreferrer\"\n                >\n                  Open PDF\n                </a>\n\n                <a className={styles.btn} href={pdfHref} download>\n                  Download\n                </a>\n              </div>\n            ) : null}\n\n            {/* Optional: keep embed for non-PDFs OR if you still want a preview */}\n            {project.embedUrl && !isPdf ? (\n  <div className={styles.embedRow}>\n    <ProjectEmbed\n      src={project.embedUrl}\n      title={`${project.title} preview`}\n    />\n  </div>\n) : null}\n\n          </header>\n\n          <article className={styles.article}>\n            <RichText content={project.longDesc} styles={styles} />\n\n            <div className={styles.ctas}>\n              {!project.comingSoon && project.href !== \"#\" ? (\n                <a\n                  className={styles.primaryCta}\n                  href={project.href}\n                  target={project.href.startsWith(\"http\") ? \"_blank\" : undefined}\n                  rel={project.href.startsWith(\"http\") ? \"noreferrer\" : undefined}\n                >\n                  Open →\n                </a>\n              ) : (\n                <div className={styles.muted}>Coming soon →</div>\n              )}\n            </div>\n          </article>\n        </div>\n      </main>\n    </div>\n  );\n}\n\n/**\n * Lightweight markdown-ish renderer.\n * Supports:\n * - \"## Heading\" -> <h2>\n * - \"- bullet\" -> <ul><li>\n * - blank lines -> paragraph separation\n */\nfunction RichText({\n  content,\n  styles,\n}: {\n  content: string;\n  styles: {\n    h2: string;\n    p: string;\n    ul: string;\n  };\n}) {\n  const lines = content.split(\"\\n\");\n\n  const blocks: Array<\n    | { type: \"h2\"; text: string }\n    | { type: \"p\"; text: string }\n    | { type: \"ul\"; items: string[] }\n  > = [];\n\n  let paragraphBuffer: string[] = [];\n  let listBuffer: string[] = [];\n\n  const flushParagraph = () => {\n    const text = paragraphBuffer.join(\" \").trim();\n    if (text) blocks.push({ type: \"p\", text });\n    paragraphBuffer = [];\n  };\n\n  const flushList = () => {\n    if (listBuffer.length) blocks.push({ type: \"ul\", items: listBuffer });\n    listBuffer = [];\n  };\n\n  for (const raw of lines) {\n    const line = raw.trim();\n\n    if (!line) {\n      flushList();\n      flushParagraph();\n      continue;\n    }\n\n    if (line.startsWith(\"## \")) {\n      flushList();\n      flushParagraph();\n      blocks.push({ type: \"h2\", text: line.replace(/^##\\s+/, \"\").trim() });\n      continue;\n    }\n\n    if (line.startsWith(\"- \")) {\n      flushParagraph();\n      listBuffer.push(line.replace(/^- /, \"\").trim());\n      continue;\n    }\n\n    flushList();\n    paragraphBuffer.push(line);\n  }\n\n  flushList();\n  flushParagraph();\n\n  return (\n    <>\n      {blocks.map((b, idx) => {\n        if (b.type === \"h2\") {\n          return (\n            <h2 key={idx} className={styles.h2}>\n              {b.text}\n            </h2>\n          );\n        }\n\n        if (b.type === \"ul\") {\n          return (\n            <ul key={idx} className={styles.ul}>\n              {b.items.map((it, j) => (\n                <li key={j}>{it}</li>\n              ))}\n            </ul>\n          );\n        }\n\n        return (\n          <p key={idx} className={styles.p}>\n            {b.text}\n          </p>\n        );\n      })}\n    </>\n  );\n}\n\nfunction pillToneClass(\n  tone: \"companies\" | \"simulation\" | \"research\",\n  styles: {\n    pillCompanies: string;\n    pillSimulation: string;\n    pillResearch: string;\n  }\n) {\n  if (tone === \"companies\") return styles.pillCompanies;\n  if (tone === \"simulation\") return styles.pillSimulation;\n  return styles.pillResearch;\n}\n"],"names":[],"mappings":";;;;;AAAA;AACA;AAAA;AAEA;AACA;AACA;AAEA;;;;;;;;AAEe,eAAe,YAAY,EACxC,MAAM,EAGP;IACC,MAAM,EAAE,IAAI,EAAE,GAAG,MAAM;IAEvB,MAAM,UAAU,IAAA,qIAAU,EAAC;IAC3B,IAAI,CAAC,SAAS,OAAO,IAAA,iMAAQ;IAE7B,MAAM,kBACJ,QAAQ,IAAI,IAAI,QAAQ,IAAI,CAAC,UAAU,CAAC,UAAU,QAAQ,IAAI,GAAG;IAEnE,MAAM,eAAe,kBACjB,gBAAgB,OAAO,CAAC,gBAAgB,IAAI,OAAO,CAAC,OAAO,MAC3D;IAEJ,MAAM,QAAQ,QAAQ,QAAQ,GAC1B,QAAQ,QAAQ,CAAC,WAAW,GAAG,QAAQ,CAAC,UACxC;IAEJ,MAAM,UAAU,QAAQ,QAAQ,QAAQ,GAAI;IAE5C,qBACE,8OAAC;QAAI,WAAW,iKAAM,CAAC,IAAI;;0BACzB,8OAAC,gIAAM;;;;;0BAEP,8OAAC;gBAAK,WAAW,iKAAM,CAAC,IAAI;0BAC1B,cAAA,8OAAC;oBAAI,WAAW,iKAAM,CAAC,KAAK;;sCAC1B,8OAAC;4BAAI,WAAW,iKAAM,CAAC,GAAG;sCACxB,cAAA,8OAAC,0LAAI;gCAAC,MAAK;gCAAI,WAAW,iKAAM,CAAC,QAAQ;0CAAE;;;;;;;;;;;sCAK7C,8OAAC;4BAAO,WAAW,iKAAM,CAAC,MAAM;;8CAC9B,8OAAC;oCAAI,WAAW,iKAAM,CAAC,SAAS;;sDAC9B,8OAAC;4CAAG,WAAW,iKAAM,CAAC,KAAK;sDAAG,QAAQ,KAAK;;;;;;sDAE3C,8OAAC;4CACC,WAAW,GAAG,iKAAM,CAAC,IAAI,CAAC,CAAC,EAAE,cAC3B,QAAQ,QAAQ,EAChB,iKAAM,GACL;sDAEF,QAAQ,IAAI;;;;;;;;;;;;8CAIjB,8OAAC;oCAAI,WAAW,iKAAM,CAAC,OAAO;;sDAC5B,8OAAC;4CAAK,WAAW,iKAAM,CAAC,QAAQ;sDAAG,QAAQ,QAAQ;;;;;;sDACnD,8OAAC;4CAAK,WAAW,iKAAM,CAAC,GAAG;sDAAE;;;;;;sDAC7B,8OAAC;4CAAK,WAAW,iKAAM,CAAC,IAAI;sDAAG,QAAQ,IAAI;;;;;;;;;;;;gCAG5C,gCACC,8OAAC;oCAAI,WAAW,iKAAM,CAAC,UAAU;;sDAC/B,8OAAC;4CAAK,WAAW,iKAAM,CAAC,YAAY;sDAAE;;;;;;sDACtC,8OAAC;4CACC,WAAW,iKAAM,CAAC,WAAW;4CAC7B,MAAM;4CACN,QAAO;4CACP,KAAI;;gDAEH;gDAAa;;;;;;;;;;;;2CAGhB;8CAEJ,8OAAC;oCAAE,WAAW,iKAAM,CAAC,GAAG;8CAAG,QAAQ,IAAI;;;;;;gCAKtC,wBACC,8OAAC;oCAAI,WAAW,iKAAM,CAAC,UAAU;;sDAC/B,8OAAC;4CACC,WAAW,iKAAM,CAAC,UAAU;4CAC5B,MAAM;4CACN,QAAO;4CACP,KAAI;sDACL;;;;;;sDAID,8OAAC;4CAAE,WAAW,iKAAM,CAAC,GAAG;4CAAE,MAAM;4CAAS,QAAQ;sDAAC;;;;;;;;;;;2CAIlD;gCAGH,QAAQ,QAAQ,IAAI,CAAC,sBAChC,8OAAC;oCAAI,WAAW,iKAAM,CAAC,QAAQ;8CAC7B,cAAA,8OAAC,sIAAY;wCACX,KAAK,QAAQ,QAAQ;wCACrB,OAAO,GAAG,QAAQ,KAAK,CAAC,QAAQ,CAAC;;;;;;;;;;2CAGnC;;;;;;;sCAIM,8OAAC;4BAAQ,WAAW,iKAAM,CAAC,OAAO;;8CAChC,8OAAC;oCAAS,SAAS,QAAQ,QAAQ;oCAAE,QAAQ,iKAAM;;;;;;8CAEnD,8OAAC;oCAAI,WAAW,iKAAM,CAAC,IAAI;8CACxB,CAAC,QAAQ,UAAU,IAAI,QAAQ,IAAI,KAAK,oBACvC,8OAAC;wCACC,WAAW,iKAAM,CAAC,UAAU;wCAC5B,MAAM,QAAQ,IAAI;wCAClB,QAAQ,QAAQ,IAAI,CAAC,UAAU,CAAC,UAAU,WAAW;wCACrD,KAAK,QAAQ,IAAI,CAAC,UAAU,CAAC,UAAU,eAAe;kDACvD;;;;;6DAID,8OAAC;wCAAI,WAAW,iKAAM,CAAC,KAAK;kDAAE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAQ9C;AAEA;;;;;;CAMC,GACD,SAAS,SAAS,EAChB,OAAO,EACP,MAAM,EAQP;IACC,MAAM,QAAQ,QAAQ,KAAK,CAAC;IAE5B,MAAM,SAIF,EAAE;IAEN,IAAI,kBAA4B,EAAE;IAClC,IAAI,aAAuB,EAAE;IAE7B,MAAM,iBAAiB;QACrB,MAAM,OAAO,gBAAgB,IAAI,CAAC,KAAK,IAAI;QAC3C,IAAI,MAAM,OAAO,IAAI,CAAC;YAAE,MAAM;YAAK;QAAK;QACxC,kBAAkB,EAAE;IACtB;IAEA,MAAM,YAAY;QAChB,IAAI,WAAW,MAAM,EAAE,OAAO,IAAI,CAAC;YAAE,MAAM;YAAM,OAAO;QAAW;QACnE,aAAa,EAAE;IACjB;IAEA,KAAK,MAAM,OAAO,MAAO;QACvB,MAAM,OAAO,IAAI,IAAI;QAErB,IAAI,CAAC,MAAM;YACT;YACA;YACA;QACF;QAEA,IAAI,KAAK,UAAU,CAAC,QAAQ;YAC1B;YACA;YACA,OAAO,IAAI,CAAC;gBAAE,MAAM;gBAAM,MAAM,KAAK,OAAO,CAAC,UAAU,IAAI,IAAI;YAAG;YAClE;QACF;QAEA,IAAI,KAAK,UAAU,CAAC,OAAO;YACzB;YACA,WAAW,IAAI,CAAC,KAAK,OAAO,CAAC,OAAO,IAAI,IAAI;YAC5C;QACF;QAEA;QACA,gBAAgB,IAAI,CAAC;IACvB;IAEA;IACA;IAEA,qBACE;kBACG,OAAO,GAAG,CAAC,CAAC,GAAG;YACd,IAAI,EAAE,IAAI,KAAK,MAAM;gBACnB,qBACE,8OAAC;oBAAa,WAAW,OAAO,EAAE;8BAC/B,EAAE,IAAI;mBADA;;;;;YAIb;YAEA,IAAI,EAAE,IAAI,KAAK,MAAM;gBACnB,qBACE,8OAAC;oBAAa,WAAW,OAAO,EAAE;8BAC/B,EAAE,KAAK,CAAC,GAAG,CAAC,CAAC,IAAI,kBAChB,8OAAC;sCAAY;2BAAJ;;;;;mBAFJ;;;;;YAMb;YAEA,qBACE,8OAAC;gBAAY,WAAW,OAAO,CAAC;0BAC7B,EAAE,IAAI;eADD;;;;;QAIZ;;AAGN;AAEA,SAAS,cACP,IAA6C,EAC7C,MAIC;IAED,IAAI,SAAS,aAAa,OAAO,OAAO,aAAa;IACrD,IAAI,SAAS,cAAc,OAAO,OAAO,cAAc;IACvD,OAAO,OAAO,YAAY;AAC5B"}}]
}